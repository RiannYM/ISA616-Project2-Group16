---
title: "Cleaning the Combined BI And Survey Career Data"
author: "Ri'ann Yates-Miller"
output:
  html_document:
    date: "`r format(Sys.time(), '%d %B, %Y')`"
    code_folding: hide
    df_print: paged
    number_sections: yes
    theme: cerulean
    toc: yes
    toc_float: yes
    code_download: true
  word_document:
    toc: no
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,message=FALSE,warning=FALSE)

#package intialization
rm(list = ls()) # clear global environment
graphics.off() # close all graphics
if(require(pacman)==FALSE) install.packages("pacman")
pacman::p_load(DataExplorer,tidyverse,readxl,zoo,stargazer,kableExtra,skimr,plotly,ggpubr,vtable,tm)
```

# Introduction and Purpose

Write something here

# Data Sources

Write something here

## Read in the data

```{r}
data=readRDS(file = "FSB_BI_Survey_2019_2021.rds")
```

# Introductory EDA

Describing each data preprocessing step with small chunks of code, output where necessary, and documentation

```{r}
summary(data)
```


```{r}
introduce(data)
```

```{r}
plot_intro(data)
```

```{r}
plot_missing(data)

##Basically I think we should keep: 
# year
# GPA.Range
# maybe major 1
# survey plans
# survey internships
# survey intern one
# maybe survey offers
# survey salary
# maybe survey dept func
```

```{r}
plot_bar(data)
```

```{r}
data = data |> 
  dplyr::select(year.x, GPA.Range, major1, survey_plans, survey_internships, survey_internone, survey_offers, survey_salary, survey_deptfunc)

data$survey_internships = as.numeric(data$survey_internships )
data$survey_offers = as.numeric(data$survey_offers)
data$year.x = as.factor(data$year.x)
data$GPA.Range = as.factor(data$GPA.Range)
data$survey_plans = as.factor(data$survey_plans)
data$survey_deptfunc = as.factor(data$survey_deptfunc)
```

```{r}
introduce(data)
```

```{r}
plot_intro(data)
```

```{r}
plot_missing(data)
```

```{r}
plot_histogram(data)
## 0, 1, more than 1 for survey_internship
```

```{r}
## what do with all the NAs. We cant really do anything with them if we dont have that data --> salary is actually a problem
## possible missing value indicator and imputation??? idk???
```


```{r}
gpa_major_sm = 
  data |> 
  dplyr::group_by(GPA.Range, major1) |>
  dplyr::summarise( 
    internships = mean(survey_internships, na.rm = TRUE), 
    offers = mean(survey_offers, na.rm = TRUE), 
    salary = mean(survey_salary, na.rm = TRUE)
  )
```

```{r}
year_sm = 
  data |> 
  dplyr::group_by(year.x) |>
  dplyr::summarise( 
    internships = mean(survey_internships, na.rm = TRUE), 
    offers = mean(survey_offers, na.rm = TRUE), 
    salary = mean(survey_salary, na.rm = TRUE)
  )
```

```{r}
gpa_major_sm
```

```{r}
year_sm
```
```{r, fig.width=25, fig.height=15}
ggplot(data = gpa_major_sm, aes(x = major1, y = salary, 
                                fill = GPA.Range)) +
  geom_bar(stat = "identity", position = position_dodge(), 
           alpha = 0.75)  +
  labs(x = "\n Major", y = "Salary\n") +
  theme(plot.title = element_text(hjust = 0.5), 
        axis.title.x = element_text(face="bold", colour="red", 
                                    size = 12),
        axis.title.y = element_text(face="bold", colour="red", 
                                    size = 12),
        legend.title = element_text(face="bold", size = 10))
```


```{r}
## Should we make all the factors dummy for the regression?

## Maybe don't need internone or dept func
```

# Data Preprocessing

Describing each data preprocessing step with small chunks of code, output where necessary, and documentation

Need to fix: 
* major1
* salary
* maybe survey plans

Beacuse salary is relatively normal, we feel it would be appropriate to imputate the mean in this dataset. However, due to the volume of missing rows, we should proceed with caution on any insights we pull from salary. 

```{r}
major_sm = 
  data |> 
  dplyr::group_by(major1) |>
  dplyr::summarise( 
    salary = mean(survey_salary, na.rm = TRUE)
  )

library(tidyr)

major_sm %>% gather(name, vals) %>% unique()
```

```{r}
majors = list(unique(data$major1))
```


```{r}
## salary by major
for (x in majors) {
  ifelse(data$major1 == as.character(x), 
  replace(data$survey_salary,
          is.na(data$survey_salary),
          mean(major_sm$salary, na.rm =TRUE)), 
  data$survey_salary = as.numeric(data$survey_salary)
  )
}
```

Major1
```{r}
unique(data$major1)
```

### Management and Leadership v. Human Capital Mgmt & Leadership v. Management and Organizations

```{r}
library(dplyr)

# Apply the correction selectively
data = data %>%
  mutate(major1 = ifelse(major1 %in% c("Management and Leadership", "Management and Organizations", "Human Capital Mgmt& Leadership"), "Human Capital Mgmt & Leadership", as.character(major1)))

# Verify the results
unique(data$major1)

```


### What is Interdisciplinary Business Management --> is a thing but I don't think it's a thing anymore

Only 13 observations and no salary data. Will skew analyses

### Entrepreneurship can only be a co-major or minor --> should include major two?

Including all major 2's adds a lot of levels. Maybe not every co-major combo, but I feel like Entrepreneurship is an important one, since it literally cannot be a single major

```{r}
data = data %>%
  mutate(major1 = ifelse(
    (major1 == "Entrepreneurship")|(major2 == "Entrepreneurship"), 
    paste0(as.character(major1), " & ", as.character(major2)), 
    as.character(major1)))

unique(data$major1)
```

### What's general business --> undecided

Only one row and almost all of that data is NA --> drop

Checking Survey Plans
```{r}
unique(data$survey_plans) 
## Looks pretty good. Could maybe just delete where it's NA since this is our response
```



# The rest of your document

Add sections and subsections as necessary to guide your analysis

